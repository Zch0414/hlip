{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af37ac36-f597-4c35-a83e-eed2e8c1848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22805d87-348e-4b12-935f-abb2f5bef01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_brats23(path):\n",
    "    def reorient(img_sitk, tgt='RPI'):\n",
    "        \"\"\"\n",
    "        Reorientation from src -> tgt for the input img.\n",
    "        Although this function is flexible enough for tgt,\n",
    "        it is important to follow the standard orientation order as:\n",
    "        'RPI' for Python; 'LPS' for 3D Slicer.\n",
    "        Parameters:\n",
    "            img: An sitk image of shape [x, y, z].\n",
    "            tgt: A string of target orentations.\n",
    "        Returns:\n",
    "            img: An sitk image after transposing.\n",
    "        \"\"\"\n",
    "        orienter = sitk.DICOMOrientImageFilter()\n",
    "        orienter.SetDesiredCoordinateOrientation(tgt)\n",
    "        return orienter.Execute(img_sitk)\n",
    "    \n",
    "    \n",
    "    img_sitk = sitk.ReadImage(path)\n",
    "    img_sitk = reorient(img_sitk, tgt='RPI')\n",
    "    img_arr = sitk.GetArrayFromImage(img_sitk) # x, y, z -> z, y, x (d, h, w)\n",
    "    return img_arr\n",
    "\n",
    "\n",
    "def load_dwi(path):\n",
    "    def transpose_raw2rpi(img, orientation):\n",
    "        orientation_transpose = []\n",
    "        try:\n",
    "            orientation_transpose.append(orientation.index('R'))\n",
    "        except ValueError:\n",
    "            orientation_transpose.append(orientation.index('L'))\n",
    "        try:\n",
    "            orientation_transpose.append(orientation.index('P'))\n",
    "        except ValueError:\n",
    "            orientation_transpose.append(orientation.index('A'))\n",
    "        try:\n",
    "            orientation_transpose.append(orientation.index('I'))\n",
    "        except ValueError:\n",
    "            orientation_transpose.append(orientation.index('S'))\n",
    "        img = np.transpose(img, orientation_transpose)\n",
    "        if 'L' in orientation:\n",
    "            img = img[::-1, :, :]\n",
    "        if 'A' in orientation:\n",
    "            img = img[:, ::-1, :]\n",
    "        if 'S' in orientation:\n",
    "            img = img[:, :, ::-1]\n",
    "        return img, orientation_transpose\n",
    "\n",
    "\n",
    "    def compute_spacing(affine, orientation_transpose):\n",
    "        spacing = np.sqrt(np.sum(affine[:3, :3] ** 2, axis=0))\n",
    "        spacing = spacing[orientation_transpose]\n",
    "        return spacing\n",
    "\n",
    "\n",
    "    def transpose_lps2dhw(img, spacing):\n",
    "        if np.unique(spacing).size == 1: # isotropic data\n",
    "            img = np.transpose(img, (2, 1, 0)) # axial\n",
    "        else:\n",
    "            _max_spacing_side = np.argmax(spacing, axis=-1)\n",
    "            if _max_spacing_side == 0: # sagittal\n",
    "                img = np.transpose(img, (0, 2, 1))\n",
    "            if _max_spacing_side == 1: # coronal\n",
    "                img = np.transpose(img, (1, 2, 0))\n",
    "            if _max_spacing_side == 2: # axial\n",
    "                img = np.transpose(img, (2, 1, 0))\n",
    "        return img\n",
    "    \n",
    "    nifti_file = nib.load(path)\n",
    "    img = nifti_file.get_fdata()\n",
    "    affine = nifti_file.affine\n",
    "    orientation = nib.orientations.aff2axcodes(affine)\n",
    "    img, orientation_transpose = transpose_raw2rpi(img[:, :, :, 0], orientation)\n",
    "    spacing = compute_spacing(affine, orientation_transpose)\n",
    "    img = transpose_lps2dhw(img, spacing)\n",
    "    return img\n",
    "\n",
    "\n",
    "def brats23_annotation(dataset):\n",
    "    root_path='/data/brats2023'\n",
    "    save_path='/data/pub_brain_5/brats23/'\n",
    "    if dataset == 'BraTS-GLI':\n",
    "        tumor_type = 'adult_glioma'\n",
    "    elif dataset == 'BraTS-MEN':\n",
    "        tumor_type = 'adult_meningioma'\n",
    "    elif dataset == 'BraTS-MET':\n",
    "        tumor_type = 'adult_metastasis'\n",
    "    elif dataset == 'BraTS-PED':\n",
    "        tumor_type = 'pediatric_glioma'\n",
    "    \n",
    "    rows = []\n",
    "    data_dir = os.path.join(root_path, dataset)\n",
    "    for dir in sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]):    \n",
    "        if 'Train' in dir:\n",
    "            save_dir = os.path.join(save_path, 'train', tumor_type)\n",
    "        elif 'Validation' in dir:\n",
    "            save_dir = os.path.join(save_path, 'test', tumor_type)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        set_dir = os.path.join(data_dir, dir)\n",
    "        print(\"Process:\", set_dir)\n",
    "        patient_ids = sorted([d for d in os.listdir(set_dir) if os.path.isdir(os.path.join(set_dir, d))])\n",
    "        for patient_id in tqdm(patient_ids):\n",
    "            patient_dir = os.path.join(set_dir, patient_id)\n",
    "            segment_path = None\n",
    "            for p in os.listdir(patient_dir):\n",
    "                if os.path.isfile(os.path.join(patient_dir, p)) and p.endswith('.nii.gz') and not p.startswith('.') and ('seg' in p.lower() or 'mask' in p.lower()):\n",
    "                    segment_path = os.path.join(patient_dir, p)\n",
    "            if segment_path is None:\n",
    "                continue\n",
    "            seg_arr = load_brats23(segment_path)\n",
    "            non_zero_slices = np.where(np.any(seg_arr != 0, axis=(1, 2)))[0]\n",
    "            row = [str(os.path.join(save_dir, patient_id)), non_zero_slices]\n",
    "            rows.append(row)\n",
    "    return rows\n",
    "    \n",
    "\n",
    "def stroke_annotation():\n",
    "    root_path = '/data/stroke/'\n",
    "    save_dir = '/data/pub_brain_5/stroke/'\n",
    "    study_ids = os.listdir(save_dir)\n",
    "    \n",
    "    rows = []\n",
    "    not_valid = []\n",
    "    for study_id in tqdm(study_ids):\n",
    "        meta_json = os.path.join(root_path, study_id, f'{study_id}_meta.json')\n",
    "        with open(meta_json, 'r') as file:\n",
    "            meta_data = json.load(file)\n",
    "        meta_study_path = meta_data['OriginalStudyPath']\n",
    "        dwi_masks_dir = meta_study_path.replace('raw_data', 'DWI_masks')\n",
    "        segment_path = None\n",
    "        for p in os.listdir(dwi_masks_dir):\n",
    "            if os.path.isfile(os.path.join(dwi_masks_dir, p)) and p.endswith('.nii.gz') and not p.startswith('.') and 'stroke_mask' in p.lower():\n",
    "                segment_path = os.path.join(dwi_masks_dir, p)\n",
    "        if segment_path == None:\n",
    "            not_valid.append(segment_path)\n",
    "            continue\n",
    "        seg_arr = load_dwi(segment_path)\n",
    "        non_zero_slices = np.where(np.any(seg_arr != 0, axis=(1, 2)))[0]\n",
    "        non_zero_slices_flip = non_zero_slices + seg_arr.shape[0]  # shift indices for the second volume\n",
    "        non_zero_slices_total = np.concatenate([non_zero_slices, non_zero_slices_flip], axis=0)\n",
    "        row = [str(os.path.join(save_dir, study_id)), non_zero_slices_total]\n",
    "        rows.append(row)\n",
    "        \n",
    "    print(f\"# valid studies: {len(rows)}; # invalid studies: {len(not_valid)}\")\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd3634-b748-4e27-9026-f047844ee5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "columns = ['study', 'target_slices']\n",
    "\n",
    "rows = []\n",
    "for dataset in ['BraTS-GLI', 'BraTS-MEN', 'BraTS-MET', 'BraTS-PED']:\n",
    "    rows.extend(brats23_annotation(dataset))\n",
    "rows.extend(stroke_annotation())\n",
    "\n",
    "df = pd.DataFrame(rows, columns=columns)\n",
    "df.to_csv('./ground_truth.csv', index=False)\n",
    "print(f\"CSV file created: ./ground_truth.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bratc",
   "language": "python",
   "name": "bratc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
